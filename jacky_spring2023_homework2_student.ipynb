{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackychen08/Self_Supervised_Learning/blob/main/jacky_spring2023_homework2_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLm_JxCxrkIE"
      },
      "source": [
        "<center> <h1> CSCI 601.471/671 NLP: Self-supervised Models </h1> </center>\n",
        "\n",
        "<center> <h2> Homework 2: Classifying Text with Word Embeddings </h2> </center>\n",
        "\n",
        "In this homework, we will build a sentiment classifier using different representational choices, providing an opportunity to apply concepts learned in class in a hands-on manner. \n",
        "\n",
        "**After this assignment you will be able to be comfortable with :**\n",
        "- the Softmax classifier and its gradients. \n",
        "- building classifiers and optimizing them with gradient descent. \n",
        "\n",
        "# Setup\n",
        "\n",
        "For this and other assignments, we will be using Google Colab, for both code as well as descriptive questions. Your task is to finish all the questions in the Colab notebook and then upload a PDF version of the notebook, and a viewable link on Gradescope.\n",
        "\n",
        "\n",
        "### Submission\n",
        "\n",
        "Before you start working on this homework do the following steps:\n",
        "\n",
        "1. Press __File > Save a copy in Drive...__ tab. This will allow you to have your own copy and change it.\n",
        "2. Follow all the steps in this collaboratory file and write / change / uncomment code as necessary.\n",
        "3. Do not forget to occasionally press __File > Save__ tab to save your progress.\n",
        "4. After all the changes are done and progress is saved press __Share__ button (top right corner of the page), press __get a shareable link__ and make sure you have the option __Anyone with the link can view__ selected. Copy the link and paste it in the box below.\n",
        "5. After completing the notebook, press __File > Download .ipynb__ to download a local copy on your computer, and then upload the file to Gradescope.\n",
        "\n",
        "\n",
        "__Paste your notebook link in the box below.__ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_yGWG2_-Sff"
      },
      "outputs": [],
      "source": [
        "# Paste your Colab notebook link here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jNA3hjUU1aM"
      },
      "source": [
        "\n",
        "Let's get started! Run the following cell to load the packages you will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwhiI6pYaX7A"
      },
      "outputs": [],
      "source": [
        "!python3 --version # to check the Python version. We have used Python 3.8.10 when preparing this assignemnt \n",
        "\n",
        "!pip install --upgrade pip # updates your pip tool to its latest version \n",
        "!pip install nltk==3.8.1 # for tokenizing text \n",
        "!pip install numpy==1.24.1 # contains many useful numercial tools \n",
        "!pip install gensim==3.6.0 # to download word embeddings \n",
        "!pip install tqdm==4.64.1 # a nice library for visualizing progress bar \n",
        "!pip install datasets==2.9.0 # huggingface's library of datasets \n",
        "\n",
        "import random # for randomizing data \n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize  # for tokenization \n",
        "import numpy as np # for numerical operators \n",
        "from tqdm import tqdm # progress bar \n",
        "import matplotlib.pyplot as plt # for plotting \n",
        "import gensim.downloader # for download word embeddings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqO0PbMcaYvW"
      },
      "source": [
        "# Tokenization and cleaning\n",
        "The first step is to **tokenize** text! \n",
        "Tokenization is the process of converting a string of text into tokens (smaller sub-strings). It is a common task in NLP and is often the first step in processing text data. Tokens can be words, phrases, or other meaningful elements of the text, depending on the application. Tokenization helps to simplify text data, making it easier to process and analyze.\n",
        "\n",
        "Take this sentence for example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMCDKnYEPAP-"
      },
      "outputs": [],
      "source": [
        "sentence = 'Who ‚ù§Ô∏è \"word embeddings\" in 2023? We do!!!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFgj0BGX8w9"
      },
      "source": [
        "Next, use NLTK's tokenization engine to split the corpus into individual tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agBRlA3aX-fo"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')  # download pre-trained Punkt tokenizer files for English\n",
        "\n",
        "print(f'Initial string:  {sentence}')\n",
        "data = nltk.word_tokenize(sentence)\n",
        "print(f'After tokenization:  {sentence}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7pg-vVSYFt4"
      },
      "source": [
        "As you can see, this function in `NLTK` turns a sentence into a list of tokens. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0wsTv_TYVR8"
      },
      "source": [
        "Now try it out yourself with your own sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PPnvEwXYWjv"
      },
      "outputs": [],
      "source": [
        "data = nltk.word_tokenize(\"YOUR SENTENCE HERE!!\")\n",
        "print(f'Result after tokenization:  {list(data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4HdgySW5p6M"
      },
      "source": [
        "# Reading the dataset \n",
        "\n",
        "For this exercise, we will use [this dataset](https://huggingface.co/datasets/imdb) which has reviews about movies that are manually annotated with positive (`label=1`) or negative reviews (`label=0`). Spend a few minutes reading few examples on Huggingfaceü§ó's to get a better sense how this dataset looks like. \n",
        "\n",
        "\n",
        "Next, we will use Huggingfaceü§ó's `datasets` library to download this dataset locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cLA3e7w5qHA"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# download dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "dataset = dataset.shuffle() # shuffle the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdAbFZWn5qOj"
      },
      "source": [
        "As you can see on Huggingfaceü§ó's website, the dataset by default comes with `test` and `train` splits. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF_Kw1Xc5qWW"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "\n",
        "print(\" -------  an example from the train set -------\")\n",
        "print(train_dataset[0])\n",
        "\n",
        "print(\" -------  an example from the test set -------\")\n",
        "print(test_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hSPgKqi5qc1"
      },
      "source": [
        "The training set is used to train the model. However, the test set is used to evaluate the model's performance. Since we don't want to overfit the test set, we will not evaluate on it more than just a few times when we are dont with model training. **This is very important**!!\n",
        "\n",
        "We wil also set aside a subset of training set as development sets. Dev sets are used in machine learning to evaluate the model's performance during the training process, providing an intermediate check on the model's accuracy before it is evaluated on the test set. \n",
        "\n",
        "Dev sets prevent overfitting during training. Overfitting occurs when a model is too complex and fits the training data too well, leading to poor performance generalization on new data. The development set allows for monitoring of the model's performance on data it has not seen during training, helping to avoid overfitting.\n",
        "\n",
        "We will also cap our train and test sets at 20k and 1k to make our training/evaluation faster, obviously at the cost of a less accuracy,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23xy-rLF5qik"
      },
      "outputs": [],
      "source": [
        "dev_dataset = train_dataset[:1000]\n",
        "train_dataset = train_dataset[1000:21000]\n",
        "test_dataset = test_dataset[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVvmIzST5qpt"
      },
      "source": [
        "To load all the inputs, we can simply call `text` key. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWGQSEWS5qv2"
      },
      "outputs": [],
      "source": [
        "train_dataset['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnGzlOmR5q14"
      },
      "source": [
        "Similarly, to extact all the outputs, we can call `label` key: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9A9ylCQ95q70"
      },
      "outputs": [],
      "source": [
        "train_dataset['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw7WD5a-5rBj"
      },
      "source": [
        "Since this is a binary classification, let's check the count of each label: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z34n4345rNA"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of positive instances: {len([x for x in train_dataset['label'] if x == 1])}\")\n",
        "print(f\"Number of negative instances: {len([x for x in train_dataset['label'] if x == 0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COvtrueR5rU4"
      },
      "source": [
        "As you can see, the labels are almost balanced. So we don't need to worry about any label imbalance issues. \n",
        "\n",
        "**Aside:** Label imbalance in machine learning is a challenge because it can result in biased models, misleading performance metrics, and degraded performance due to over/under-sampling. A model trained on imbalanced data may be more accurate for the majority class and less accurate for the minority class. Common metrics such as accuracy may not be suitable for imbalanced data sets. To address label imbalance, techniques such as over-sampling, under-sampling, or class-specific cost metrics may need to be used, which can impact the model's performance.\n",
        "\n",
        "\n",
        "# Building the feature vectors \n",
        "Here we will turn the input sentences into continuous vectors. \n",
        "To do so, we will start by loading a vector representation. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixgZ6Fb85ran"
      },
      "outputs": [],
      "source": [
        "embeddings = gensim.downloader.load('glove-twitter-50')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDgmBXj-5w_X"
      },
      "source": [
        "For each sentence, we will tokenize it and create feature vectors that is the mean of the embeddings of its tokens. Here is an example: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOJ4T8xl5xHK"
      },
      "outputs": [],
      "source": [
        "vectors = []\n",
        "for word in nltk.word_tokenize(sentence):\n",
        "    # look up embedding for the words; if not found, throws KeyError if word not found\n",
        "    try:\n",
        "        vectors.append(embeddings[word])\n",
        "    except KeyError:\n",
        "        pass\n",
        "features = np.array(vectors).mean(axis=0)  # average the vectors\n",
        "\n",
        "# append a bias term to features[senId]\n",
        "np.append(features, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnRyMwsg5xMp"
      },
      "source": [
        "Note that this feature vector has dimension 51, which is the same as the original embedding dimensions plus one. The added one is usually called a bias term. Since we are going to use a linear classifier, the bias term allows the model to shift the decision boundary away from the origin, so it can better fit the data and improve classification accuracy. \n",
        "\n",
        "Next, we will build a function to featurize all of our data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REanCCs9LUjw"
      },
      "outputs": [],
      "source": [
        "def featurizer(data, embeddings):\n",
        "    # determine the dimensionality of vectors\n",
        "    feature_length = embeddings['the'].shape[0] + 1 # plus 1 for the bias term \n",
        "\n",
        "    features = np.zeros((len(data), feature_length)) # a feature vector for the whole data \n",
        "    empty_count = 0\n",
        "    for senId, sentence in tqdm(enumerate(data)):\n",
        "        vectors = []\n",
        "        for word in nltk.word_tokenize(sentence) :\n",
        "            # look up embedding for the words; if not found, throws KeyError if word not found\n",
        "            try:\n",
        "                vectors.append(embeddings[word])\n",
        "            except KeyError:\n",
        "                pass\n",
        "        if len(vectors) > 0:\n",
        "            feature_vector = np.array(vectors).mean(axis=0)  # average the vectors\n",
        "            features[senId] = np.append(feature_vector, 1.0) # bias term \n",
        "        else:\n",
        "            empty_count += 1\n",
        "    print(\"Numer of samples with no words found: %s / %s\" % (empty_count, len(data)))\n",
        "    return features\n",
        "\n",
        "\n",
        "\n",
        "# bag of embeddings features \n",
        "train_input_embeddings = featurizer(train_dataset['text'], embeddings=embeddings)\n",
        "dev_input_embeddings = featurizer(dev_dataset['text'], embeddings=embeddings)\n",
        "test_input_embeddings = featurizer(test_dataset['text'], embeddings=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg_II5_QLUqw"
      },
      "source": [
        "## **Question 1:** Explain what `featurizer` function does. (no more than 5 sentences). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIEJG-ypLUyz"
      },
      "outputs": [],
      "source": [
        "# Your answer here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pGAi5mWLU6n"
      },
      "source": [
        "Let's also pull out the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JbCI6ADLVBs"
      },
      "outputs": [],
      "source": [
        "train_labels = np.array(train_dataset['label'])\n",
        "dev_labels = np.array(dev_dataset['label'])\n",
        "test_labels = np.array(test_dataset['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_It-c29LRLk"
      },
      "source": [
        "# Softmax function\n",
        "Remember the Softmax function that turns real-valued score is turned into probabilities:\n",
        "\n",
        "$$\n",
        "   \\sigma(\\mathbf{z}) = \\frac{\\exp(z_j)}{\\sum_k \\exp(z_k)}\n",
        "$$\n",
        "\n",
        "\n",
        "## **Question 2:** Implement the softmax function to turn any vector $\\mathbf{z}$ (numpy array) into probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-FaBhd05xSn"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Compute the softmax function for each row of the input x.\n",
        "\n",
        "    It is crucial that this function is optimized for speed because\n",
        "    it will be used frequently in later code.\n",
        "    You might find numpy functions np.exp, np.sum, np.reshape,\n",
        "    np.max, and numpy broadcasting useful for this task. (numpy\n",
        "    broadcasting documentation:\n",
        "    http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
        "\n",
        "    You should also make sure that your code works for one\n",
        "    dimensional inputs (treat the vector as a row), you might find\n",
        "    it helpful for your later problems.\n",
        "\n",
        "    You must implement the optimization in problem 4.1 (\"pro tip\") of the \n",
        "    written assignment!\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE (should be 2-4 lines)\n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijqLnvvD5xd4"
      },
      "source": [
        "If your implementation is correct, it should pass the following test cases. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0P1mNQA5xlo"
      },
      "outputs": [],
      "source": [
        "print(\"Running basic tests...\")\n",
        "test1 = softmax(np.array([1,2]))\n",
        "print(test1)\n",
        "assert np.amax(np.fabs(test1 - np.array([0.26894142,  0.73105858]))) <= 1e-6\n",
        "\n",
        "test2 = softmax(np.array([[1001,1002],[3,4]]))\n",
        "print(test2)\n",
        "assert np.amax(np.fabs(test2 - np.array([[0.26894142, 0.73105858], [0.26894142, 0.73105858]]))) <= 1e-6\n",
        "\n",
        "test3 = softmax(np.array([[-1001,-1002]]))\n",
        "print(test3)\n",
        "assert np.amax(np.fabs(test3 - np.array([0.73105858, 0.26894142]))) <= 1e-6\n",
        "\n",
        "print(\" >> If you got here, the tests passed! GREAT!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN7r6i0QPXAg"
      },
      "source": [
        "Now, let's experiment with the `softmax()` to understand its function. We will design a function to visualize the input/output of softmax: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQdAs9XoTB9M"
      },
      "outputs": [],
      "source": [
        "def visualize_softmax(x):\n",
        "    y = softmax(x)\n",
        "\n",
        "    plt.bar(range(len(x)), x, alpha=0.4)\n",
        "    plt.bar(range(len(y)), y, color='r', alpha=0.3)\n",
        "\n",
        "    plt.legend(['Input to Softmax', 'Output of Softmax'])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqxF5IJKTUCi"
      },
      "source": [
        "Here are a couple of inputs and their visualizations: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbJPa_JITUKC"
      },
      "outputs": [],
      "source": [
        "visualize_softmax(np.array([0.5, 0.5]))\n",
        "visualize_softmax(np.array([0.1, 0.1]))\n",
        "visualize_softmax(np.array([0.9, 0.9]))\n",
        "visualize_softmax(np.array([0.26894142, 0.73105858]))\n",
        "visualize_softmax(2 * np.array([0.26894142, 0.73105858]))\n",
        "visualize_softmax(0.5 * np.array([0.26894142, 0.73105858]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzXslB6tT35W"
      },
      "source": [
        "## **Question 3:** Interpret the behavior of `softmax` function with the help of above examples (no more than 4 sentences). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiM3mW28fQXH"
      },
      "outputs": [],
      "source": [
        "# your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjNQk55_Uxy8"
      },
      "source": [
        "# Turning Softmax into a classifier \n",
        "\n",
        "We will build a classifier now. \n",
        "Let's remember the structure of the softmax linear classifier: the input vector $\\mathbf{x}$ is transformed into a **logit score** vector $\\mathbf{z}$ using a weight matrix $W$ and a bias vector $\\mathbf{b}$:\n",
        "\n",
        "$$\n",
        "    \\mathbf{z} = \\mathbf{x} W \n",
        "$$\n",
        "\n",
        "This logit score has one element per class, so the weight matrix must have a size $(d, c)$, where $c$ is the number of classes (output labels) and $d$ is the number of dimensions of the input space (features). The bias vector has $c$ elements (one per class).\n",
        "\n",
        "The logit score is turned into probabilities using the **softmax** operator:\n",
        "\n",
        "$$\n",
        "    \\hat{y}_j = P(\\text{class = j}) = \\frac{\\exp(z_j)}{\\sum_k \\exp(z_k)}\n",
        "$$\n",
        "\n",
        "Let's initialize a rando weight vector first and classify our instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiMQPb91dCc5"
      },
      "outputs": [],
      "source": [
        "num_classes = 2 # number of output classes \n",
        "dimVectors = train_input_embeddings[0].shape[0] # loop up the feature dimension \n",
        "weights = 0.1 * np.random.randn(dimVectors, num_classes) # a random weight vector \n",
        "\n",
        "prob = softmax(train_input_embeddings.dot(weights))\n",
        "pred = np.argmax(prob, axis=1)\n",
        "\n",
        "prob, prob.shape, pred "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW4j782edClQ"
      },
      "source": [
        "You should be able to see that the probabilities produced by this classifier are: \n",
        " - all in between 0 and 1 \n",
        " - have two columns (one for each class) which sum to 1.0 \n",
        " - have 20k rows, which is the same dimension as the number of our training instances -- one output per each input. \n",
        " - `pred` contains the class index with the highest probability. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MElI7hiXexE2"
      },
      "source": [
        "How good is this classifier? Let's build a function that measures the accuracy of this classifier, i.e., the rate at which the classifier output equals the gold label. \n",
        "\n",
        "\n",
        "## **Question 4:** complete the following function for accuracy: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewbhAB6WdCxR"
      },
      "outputs": [],
      "source": [
        "def accuracy(y, yhat):\n",
        "    assert (y.shape == yhat.shape)\n",
        "    \n",
        "    # for checking equility between numpy arrays we can use == operator \n",
        "    # for summing values we can use np.sum() function \n",
        "\n",
        "    ## START CODE HERE (hint: 1-2 lines of code)\n",
        "    ## END CODE HERE \n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJHLLVvgOB4"
      },
      "source": [
        "If your implementation is right, it should pass the following tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEl_OYGygOIn"
      },
      "outputs": [],
      "source": [
        "# perfect prediction --> 100% \n",
        "assert np.abs(\n",
        "    np.fabs(accuracy(np.array([0, 3, 1, 2, 5]), np.array([0, 3, 1, 2, 5])) - \n",
        "            np.array(100.0))) < 1e-6\n",
        "\n",
        "# all incorrect --> 0% \n",
        "assert np.abs(\n",
        "    np.fabs(accuracy(np.array([0, 1, 1, 0, 0]), np.array([1, 0, 0, 1, 1])) - \n",
        "            np.array(0.0))) < 1e-6\n",
        "\n",
        "print(\"if you got here, your implementation for accuracy is probably correct! \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY1mbUpfh6dv"
      },
      "source": [
        "Now let's evaluate our predictions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCt_SXMuh6mR"
      },
      "outputs": [],
      "source": [
        "accuracy(train_labels, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNLZ5h-iLbL"
      },
      "source": [
        "How bad is this number? Pretty bad! Given that our data is balanced, a random coin toss would result in 50% performance, which is the performance floor for any classifier we build. To improve our classifier, we will run an optimization algorithm on its parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsKmF_hHipO_"
      },
      "source": [
        "# Optimizing our classifier \n",
        "\n",
        "We will start by definition an objective function that defines \"goodness\" for our classifier. \n",
        "A common choice for classification is [categorical cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy) or negative log-likelihood. \n",
        "\n",
        "A discussion or derivation of cross-entropy loss is beyond the scope of this class but a good introduction to it can be [found here](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/). A discussion of what makes it superior to MSE for classification can be found [here](https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/).  We will just focus on its properties instead.\n",
        "\n",
        "Letting $y_i$ denote the ground truth value of class $i$, and $\\hat{y}_i$ be our prediction of class $i$, the cross-entropy loss is defined as:\n",
        "\n",
        "$$ CE(y, \\hat{y}) = -\\sum_{i} y_i \\log \\hat{y}_i $$\n",
        "\n",
        "If the number of classes is 2 (which is the case here), we can expand this:\n",
        "\n",
        "$$ CE(y, \\hat{y}) = -{(y\\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y}))}\\ $$\n",
        "\n",
        "Notice that as our probability for the predicting the correct class approaches 1, the cross-entropy approaches 0. For example, if $y=1$, then as $\\hat{y}\\rightarrow 1$, $CE(y, \\hat{y}) \\rightarrow 0$. If our probability for the correct class approaches 0 (the exact wrong prediction), e.g. if $y=1$ and $\\hat{y} \\rightarrow 0$, then $CE(y, \\hat{y}) \\rightarrow \\infty$.\n",
        "\n",
        "This is true in the more general $M$-class cross-entropy loss as well, $CE(y, \\hat{y}) = -\\sum_{i} y_i \\log \\hat{y}_i $, where if our prediction is very close to the true label, then the entropy loss is close to 0, whereas the more dissimilar the prediction is to the true class, the higher it is.\n",
        "\n",
        "**Practical tip:** in practice, a very small $\\epsilon$ is added to the log, e.g. $\\log(\\hat{y}+\\epsilon)$ to avoid $\\log 0$ which is undefined.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFnh_LI78r-4"
      },
      "source": [
        "Let's compute CE loss for the cross entropy loss: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiArBqOS5vTZ"
      },
      "outputs": [],
      "source": [
        "N = train_input_embeddings.shape[0]\n",
        "cost = np.sum(-np.log(prob[range(N), train_labels])) / N\n",
        "\n",
        "# also add a regularization term \n",
        "regularization = 0.5 # the hyperparameter \n",
        "cost += 0.5 * regularization * np.sum(weights ** 2)\n",
        " \n",
        "print(f\"Overall loss for our intiail weights: {cost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8JvYxaB5vZb"
      },
      "source": [
        "Note the the latter half adds an l2 regularization term $\\frac{r}{2}\\|W\\|^2_2$ to the overall objective, where $r$ is a hyperparameter we will tune. It helps to prevent overfitting by adding a term to the loss function that discourages large weights. The result is a model that is less sensitive to the specific training data and can generalize better to new data. You can read more regularization [here](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJaPUHmP9W2V"
      },
      "source": [
        "To optimize this objective, we will compute its gradients with respect parameters $W$. \n",
        "\n",
        "\n",
        "Before doing that, let's redefine softmax + regularization in matrix form, for all classes: \n",
        "$$\n",
        "    \\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) =   - \\frac{1}{N} \\sum_{i} \\big[ \\mathbf{y}_i  \\cdot \\log \\hat{\\mathbf{y}}_i \\big] + \\frac{r}{2}\\|W\\|^2_2,\n",
        "$$\n",
        "where the summation is over $N$ many input-output instances, $\\mathbf{y}_i \\in \\{0, 1\\}^{c}$ is a one-hot encoding of the class label, and $\\hat{\\mathbf{y}}_i \\in [0, 1]^{c}$ is the matrix of probabilities assigned to each class.\n",
        "\n",
        "\n",
        "After doing the derivations, we obtain the gradient with respect to $W$:\n",
        "$$\n",
        " \\frac{\\partial \\mathcal{L} }{\\partial W} = \\frac{1}{N} \\sum_{i} \\big[ \\mathbf{x}_i^\\top (\\mathbf{y}_i - \\hat{\\mathbf{y}}_i) \\big] + r W.\n",
        "$$\n",
        "Verify the correctness of this gradient in your own time! :)  Note that because $W$ is a $(d, c)$ matrix, $\\frac{\\partial \\mathcal{L} }{\\partial W}$ too. $\\mathbf{x}_i^\\top(\\mathbf{y}_i - \\hat{\\mathbf{y}}_i)$ is therefore the **outer product** between the error vector $\\mathbf{y}_i - \\hat{\\mathbf{y}}_i$ ($c$ elements) and the input vector $\\mathbf{x}$ ($d$ elements).\n",
        "\n",
        "For more efficiency, we can write the above expression in matrix form:\n",
        "$$\n",
        " \\frac{\\partial \\mathcal{L} }{\\partial W} = \\frac{1}{N}  \\mathbf{X}^\\top (\\hat{\\mathbf{Y}} - \\mathbf{Y}) + r W,\n",
        "$$\n",
        "where $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$ is the feature matrix of all our instances,   \n",
        "$\\mathbf{Y} \\in \\{0, 1\\}^{N\\times c}$ is the matrix of gold labels (one-hot vector for each instance), \n",
        "$\\mathbf{Y} \\in [0, 1]^{N\\times c}$ is the matrix of probabilities for all of our instances.  \n",
        "\n",
        "\n",
        "Now, let's put all these together and implement a function for our softmax classifier: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh_4yp0KFOyU"
      },
      "outputs": [],
      "source": [
        "def softmax_classifier(features, labels, weights, regularization=1.0, nopredictions=False):\n",
        "    \"\"\" Multi-class softmax classifier\n",
        "        Implement softmax regression with weight regularization.\n",
        "    \n",
        "    Inputs:\n",
        "    - features: feature vectors, each row is a feature vector\n",
        "    - labels: labels corresponding to the feature vectors\n",
        "    - weights: weights of the regressor\n",
        "    - regularization: L2 regularization constant\n",
        "    - nopredictions: if True, do not compute predictions (used in q4_sgd)\n",
        "        \n",
        "    Output:\n",
        "    - cost: cost of the regressor\n",
        "    - grad: gradient of the regressor cost with respect to its weights\n",
        "    - pred: label predictions of the regressor (you might find np.argmax helpful)\n",
        "    - prob: label probabilities of the regressor  \n",
        "    \"\"\"\n",
        "\n",
        "    prob = softmax(features.dot(weights))\n",
        "    pred = np.argmax(prob, axis=1)\n",
        "    \n",
        "    if len(features.shape) > 1:\n",
        "        N = features.shape[0]\n",
        "    else:\n",
        "        N = 1\n",
        "    # A vectorized implementation of    1/N * sum(cross_entropy(x_i, y_i)) + 1/2*|w|^2\n",
        "    cost = np.sum(-np.log(prob[range(N), labels])) / N\n",
        "    cost += 0.5 * regularization * np.sum(weights ** 2)\n",
        "\n",
        "    one_hot = np.zeros_like(prob)\n",
        "    one_hot[range(N), labels] = 1\n",
        "\n",
        "    # Code the gradient computation \n",
        "    # Consider using np.dot() for dot product and .T for transpose \n",
        "    ### YOUR CODE HERE (hint: 1-2 lines)\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    if nopredictions:\n",
        "        return cost, grad\n",
        "    else:\n",
        "        return cost, grad, pred, prob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th_yRl9fMhIZ"
      },
      "source": [
        "## **Question 5:** implement the gradient calculations for our classifier according its matrix for given earlier. \n",
        "\n",
        "if your implementation is correct, the following tests should pass: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJDEnb-1SZ9b"
      },
      "outputs": [],
      "source": [
        "weights = np.array(\n",
        "    [\n",
        "        [1, 1], \n",
        "        [1, 1], \n",
        "        [1, 1]\n",
        "     ]\n",
        "    )\n",
        "features = np.array(\n",
        "      [\n",
        "        [1, 1, 1], \n",
        "        [0, 0, 0], \n",
        "        [0.5, 1, 0]\n",
        "     ]\n",
        "    )\n",
        "labels = np.array([1, 0, 1])\n",
        "cost, grad = softmax_classifier(features, labels, weights, regularization=1.0, nopredictions=True)\n",
        "\n",
        "assert np.abs(np.fabs(cost - 3.693147180)) < 1e-6\n",
        "assert np.sum(np.abs(np.fabs(grad - np.array([[1.25      , 0.75      ],\n",
        "                                    [1.33333333, 0.66666667],\n",
        "                                    [1.16666667, 0.83333333]])))) < 1e-4\n",
        "\n",
        "print(\" >>> If no error occurred, you did it right! Hurray!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOD-FqDiR-Yl"
      },
      "source": [
        "Now let's try running gradient descent and see whether our error chart goes down: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm7e-eqq5vgJ"
      },
      "outputs": [],
      "source": [
        "num_classes = 2 # number of output classes \n",
        "dimVectors = train_input_embeddings[0].shape[0] # loop up the feature dimension \n",
        "weights = 0.1 * np.random.randn(dimVectors, num_classes) # a random weight vector \n",
        "\n",
        "step_size = 0.1\n",
        "step_size_decay = 0.95\n",
        "num_steps = 50\n",
        "\n",
        "dev_cost_per_step = []\n",
        "dev_accuracy_per_step = []\n",
        "best_dev_cost = np.inf\n",
        "best_weights = None\n",
        "for step in range(num_steps):\n",
        "    cost, grad = softmax_classifier(train_input_embeddings, train_labels, weights, nopredictions=True)\n",
        "\n",
        "    # update weights with the gradients\n",
        "    weights -= step_size * grad\n",
        "\n",
        "    # decay the step size\n",
        "    step_size *= step_size_decay\n",
        "\n",
        "    # cost on the dev set validation set\n",
        "    dev_cost, _, pred, _ = softmax_classifier(dev_input_embeddings, dev_labels, weights)\n",
        "    dev_cost_per_step.append(dev_cost)\n",
        "    dev_accuracy = accuracy(dev_labels, pred)\n",
        "    dev_accuracy_per_step.append(dev_accuracy)\n",
        "\n",
        "\n",
        "# create a plot with two subplots: one for validation and the other for accuracy\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax1.plot(dev_cost_per_step)\n",
        "ax1.set_title(\"Validation Cost\")\n",
        "ax1.set_xlabel(\"Step\")\n",
        "ax1.set_ylabel(\"Cost\")\n",
        "ax2.plot(dev_accuracy_per_step)\n",
        "ax2.set_title(\"Validation Accuracy\")\n",
        "ax2.set_xlabel(\"Step\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "fig.suptitle(\"Step Size Decay: %s, Initial Step Size: %s\" % (step_size_decay, step_size))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk0SJpKE5vrs"
      },
      "source": [
        "You should be able to see that the cost is going down as a function of training iterations, which shows that our algorithm is work. Yay! \n",
        "\n",
        "However, if you repeat this, you'd notice that the accuray on the dev set is sensitive to random initializations. It is also sensitive to the choice of hyperparameters such as `step_size`. These highlight the impotance of hyperparameter tuning! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xbcURtmYBh4"
      },
      "source": [
        "# Hyperparamers \n",
        "\n",
        "Hyperparameter tuning is the process of selecting optimal values for the hyperparameters of a machine learning model to improve its performance on a given task. It's important because the performance of a model can be significantly influenced by the choice of hyperparameters, and finding the best set of hyperparameters can improve the accuracy, reduce overfitting, and increase the generalization ability of the model.\n",
        "\n",
        "To do hyperparameter tuning, let's put a wrapper around our training function and expose its parameters: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtnL4d7K5vzM"
      },
      "outputs": [],
      "source": [
        "def trainer(\n",
        "        step_size_decay, initial_step_size, num_classes, num_steps,\n",
        "        train_input_embeddings, train_labels, dev_input_embeddings, dev_labels, **kwargs\n",
        "):\n",
        "    '''\n",
        "    Trains a softmax classifier on the data\n",
        "    :param step_size_decay: step size decay\n",
        "    :param initial_step_size: initial step size\n",
        "    :param num_classes: number of classes\n",
        "    :param num_steps: number of steps\n",
        "    :param train_input_embeddings: training input embeddings\n",
        "    :param train_labels: training labels\n",
        "    :param dev_input_embeddings: development input embeddings\n",
        "    :param dev_labels: development labels\n",
        "    :return: the best weights and its corresponding cost on dev set \n",
        "    '''\n",
        "\n",
        "    # initialize weight vector randomly\n",
        "    dimVectors = train_input_embeddings[0].shape[0]\n",
        "    model_weights = 0.1 * np.random.randn(dimVectors, num_classes)\n",
        "\n",
        "    step_size = initial_step_size\n",
        "\n",
        "    dev_cost_per_step = []\n",
        "    dev_accuracy_per_step = []\n",
        "    best_dev_cost = np.inf\n",
        "    best_weights = None\n",
        "    for step in range(num_steps):\n",
        "        cost, grad, _, _ = softmax_classifier(train_input_embeddings, train_labels, model_weights)\n",
        "\n",
        "        # update weights with the gradients\n",
        "        model_weights -= step_size * grad\n",
        "\n",
        "        # decay the step size\n",
        "        step_size *= step_size_decay\n",
        "\n",
        "        # accuracy on validation set\n",
        "        dev_cost, _, pred, _ = softmax_classifier(dev_input_embeddings, dev_labels, model_weights)\n",
        "        if dev_cost < best_dev_cost:\n",
        "            best_dev_cost = dev_cost\n",
        "            best_weights = model_weights\n",
        "\n",
        "        dev_cost_per_step.append(dev_cost)\n",
        "\n",
        "        dev_accuracy = accuracy(dev_labels, pred)\n",
        "        dev_accuracy_per_step.append(dev_accuracy)\n",
        "\n",
        "    assert best_weights is not None, \"best_weights is None\"\n",
        "    return dev_cost_per_step, dev_accuracy_per_step, best_weights, best_dev_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24mXfYAf5v49"
      },
      "source": [
        "First, let's try to better understand the effect step size and its decay. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNMAO9VFbW2S"
      },
      "outputs": [],
      "source": [
        "dimVectors = train_input_embeddings[0].shape[0] # loop up the feature dimension \n",
        "weights = 0.1 * np.random.randn(dimVectors, num_classes) # a random weight vector \n",
        "\n",
        "features = {\n",
        "    'train_input_embeddings': train_input_embeddings, \n",
        "    'train_labels': train_labels, \n",
        "    'dev_input_embeddings': dev_input_embeddings, \n",
        "    'dev_labels': dev_labels\n",
        "}\n",
        "\n",
        "decay = 0.95\n",
        "\n",
        "for step in [0.002, 0.2, 2.0]:\n",
        "  dev_cost_per_step, dev_accuracy_per_step, _, _ = trainer(decay, step, \n",
        "                                                           num_classes=2, \n",
        "                                                           num_steps=50, **features)\n",
        "  \n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))  \n",
        "  # plot the cost\n",
        "  ax1.plot(dev_cost_per_step)\n",
        "  ax1.set_title(\"Validation Cost\")\n",
        "  ax1.set_xlabel(\"Step\")\n",
        "  ax1.set_ylabel(\"Cost\")\n",
        "  # plot the accuracy per step\n",
        "  ax2.plot(dev_accuracy_per_step)\n",
        "  ax2.set_title(\"Validation Accuracy\")\n",
        "  ax2.set_xlabel(\"Step\")\n",
        "  ax2.set_ylabel(\"Accuracy\")\n",
        "  # set title\n",
        "  fig.suptitle(\n",
        "      \"Step Size Decay: %s, Initial Step Size: %s\" % (decay, step))\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpgfyLASbW9u"
      },
      "source": [
        "## **Question 6:** explain the above plots in the context of following plot below shown in our lectures (no more than 5 sentences): \n",
        "\n",
        "![step-size.png](https://self-supervised.cs.jhu.edu/sp2023/files/step-size.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5p2a7JUbXFi"
      },
      "outputs": [],
      "source": [
        "# your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7k-9ZOZfuJp"
      },
      "source": [
        "Let's also look into the effect of the **decay** parameter. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWidn59giGGL"
      },
      "outputs": [],
      "source": [
        "dimVectors = train_input_embeddings[0].shape[0] # loop up the feature dimension \n",
        "weights = 0.1 * np.random.randn(dimVectors, num_classes) # a random weight vector \n",
        "\n",
        "features = {\n",
        "    'train_input_embeddings': train_input_embeddings, \n",
        "    'train_labels': train_labels, \n",
        "    'dev_input_embeddings': dev_input_embeddings, \n",
        "    'dev_labels': dev_labels\n",
        "}\n",
        "\n",
        "step = 0.2\n",
        "\n",
        "for decay in [0.8, 0.95, 1.0]:\n",
        "  dev_cost_per_step, dev_accuracy_per_step, _, _ = trainer(decay, step, \n",
        "                                                           num_classes=2, \n",
        "                                                           num_steps=50, **features)\n",
        "  \n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))  \n",
        "  # plot the cost\n",
        "  ax1.plot(dev_cost_per_step)\n",
        "  ax1.set_title(\"Validation Cost\")\n",
        "  ax1.set_xlabel(\"Step\")\n",
        "  ax1.set_ylabel(\"Cost\")\n",
        "  # plot the accuracy per step\n",
        "  ax2.plot(dev_accuracy_per_step)\n",
        "  ax2.set_title(\"Validation Accuracy\")\n",
        "  ax2.set_xlabel(\"Step\")\n",
        "  ax2.set_ylabel(\"Accuracy\")\n",
        "  # set title\n",
        "  fig.suptitle(\n",
        "      \"Step Size Decay: %s, Initial Step Size: %s\" % (decay, step))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddgC8PwTigy7"
      },
      "source": [
        "As we can see in the results, reducing the learning rate over time via the decay parameter, helps the model converge to the optimal solution more efficiently and avoid getting stuck in suboptimal solutions. In the last plot, for example, where there is no decay, the optimization is stuck and oscillating. \n",
        "\n",
        "---\n",
        "\n",
        "Okay, now that we know these hyperparameters matter, let's write a function for trying out a range of hyperparameters.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s57m9JeI5v_Z"
      },
      "outputs": [],
      "source": [
        "# hyper-parameter sweep\n",
        "def run_hyperparameter_tuning(features, log=True):\n",
        "    best_selected_weights = None\n",
        "    best_selected_cost = np.inf\n",
        "\n",
        "    # hyper-parameter sweep\n",
        "    for step in [0.02, 0.2, 2.0]:\n",
        "        for decay in [0.8, 0.90, 0.95]:\n",
        "            dev_cost_per_step, dev_accuracy_per_step, best_weights, best_dev_cost = \\\n",
        "                trainer(step_size_decay=decay, initial_step_size=step, num_classes=2, num_steps=100, **features)\n",
        "\n",
        "            if best_selected_cost > best_dev_cost:\n",
        "                if log: \n",
        "                  print(f\" -> Revising the best cost on dev from {best_selected_cost} to {best_dev_cost} \")\n",
        "                best_selected_cost = best_dev_cost\n",
        "                best_selected_weights = best_weights\n",
        "                \n",
        "\n",
        "    test_labels = features['test_labels']\n",
        "    test_input_embeddings = features['test_input_embeddings']\n",
        "\n",
        "    _, _, best_pred, _ = softmax_classifier(dev_input_embeddings, dev_labels, best_weights)\n",
        "\n",
        "    # evaluate the best model on the test set\n",
        "    test_cost, _, pred, pred_prob = softmax_classifier(test_input_embeddings, test_labels, best_selected_weights)\n",
        "    test_accuracy = accuracy(test_labels, pred)\n",
        "    print(\"Test Cost: %s\" % test_cost)\n",
        "    print(\"Test Accuracy: %s\" % test_accuracy)\n",
        "    return test_accuracy\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OUV4YYtdDHn"
      },
      "source": [
        "Let's do hyperparameter tuning on our data! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV79PmrvdDOs"
      },
      "outputs": [],
      "source": [
        "features = {\n",
        "    'train_input_embeddings': train_input_embeddings, \n",
        "    'train_labels': train_labels, \n",
        "    'dev_input_embeddings': dev_input_embeddings, \n",
        "    'dev_labels': dev_labels, \n",
        "    'test_input_embeddings': test_input_embeddings, \n",
        "    'test_labels': test_labels, \n",
        "}\n",
        "\n",
        "run_hyperparameter_tuning(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h0urDGk5rhE"
      },
      "source": [
        "Awesome, now that is the performance of our classifier the test set of this task. Notice that \n",
        " - this performance is much higher than the random chance performance 50%, which is great news!\n",
        " - we evaluate the test set only once thus far. We should always minimize the number of times we see/evaluate the test set to avoid overfitting it.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2CB4mmIk4ju"
      },
      "source": [
        "# Effect of word embeddings \n",
        "\n",
        "What happens if we use a different word embeddings? We will look into this problem now.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI4Ko1AM5r0o"
      },
      "outputs": [],
      "source": [
        "# note: this might take 15-30 minutes \n",
        "\n",
        "for embedding_type in [\"glove-twitter-50\", \"glove-twitter-100\", \"glove-twitter-200\", \"word2vec-google-news-300\"]: \n",
        "  print(f\" ============= Embedding: {embedding_type} ============ \")\n",
        "  embeddings = gensim.downloader.load(embedding_type)\n",
        "\n",
        "  # re-extract the features using this particular embedding \n",
        "  train_input_embeddings = featurizer(train_dataset['text'], embeddings=embeddings)\n",
        "  dev_input_embeddings = featurizer(dev_dataset['text'], embeddings=embeddings)\n",
        "  test_input_embeddings = featurizer(test_dataset['text'], embeddings=embeddings)\n",
        "\n",
        "  # package the embeddings for hyperparameter tuning \n",
        "  features = {\n",
        "      'train_input_embeddings': train_input_embeddings, \n",
        "      'train_labels': train_labels, \n",
        "      'dev_input_embeddings': dev_input_embeddings, \n",
        "      'dev_labels': dev_labels, \n",
        "      'test_input_embeddings': test_input_embeddings, \n",
        "      'test_labels': test_labels, \n",
        "  }\n",
        "\n",
        "  run_hyperparameter_tuning(features, log=False)\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1S5Uh_L5r62"
      },
      "source": [
        "## **Question 7:** what are your takeaways from the above experiment on trying different embeddings? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EolZt5f_5sBn"
      },
      "outputs": [],
      "source": [
        "# your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xY5UhQDVfZ1"
      },
      "source": [
        "### Congratulations!\n",
        "\n",
        "You've come to the end of this assignment. Here are the main points you should remember:\n",
        "\n",
        "- Using pre-trained **word embeddings** from the internet is often a good way to get started. \n",
        "- **Softmax classifer** is a simple, yet effective tool for multi-class problems. It is often used in conjunction with cross-entropy loss. \n",
        "- To make your implementation more efficient, use **matrix/vector operations** rather than scalar operators.  \n",
        "- Careful **hyperparameter tuning** is necessary for any statistical learning problem. \n",
        "- It is essential to evaluate the test set as minimally as you can. Instead, use the held-out development set. \n",
        "\n",
        "Congratulations on finishing the graded portions of this notebook! \n"
      ]
    }
  ]
}